{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 'xml_testing/pm_parser.py'\n",
    "#From https://github.com/titipata/pubmed_parser\n",
    "#Citation: Titipat Achakulvisut, Daniel E. Acuna (2015) \"Pubmed Parser\" http://github.com/titipata/pubmed_parser\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "from operator import is_not\n",
    "from lxml.etree import tostring\n",
    "from ast import *\n",
    "\n",
    "# from compiler.ast import flatten\n",
    "\n",
    "__all__ = [\n",
    "    'list_xml_path',\n",
    "    'parse_pubmed_xml',\n",
    "    'parse_pubmed_xml_to_df',\n",
    "    'pretty_print_xml',\n",
    "]\n",
    "\n",
    "\n",
    "def list_xml_path(path_dir):\n",
    "    \"\"\"\n",
    "    List full xml path under given directory `path_dir`\n",
    "    \"\"\"\n",
    "    fullpath = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(path_dir)) for f in fn]\n",
    "    path_list = [folder for folder in fullpath if os.path.splitext(folder)[-1] == ('.nxml' or '.xml')]\n",
    "    return path_list\n",
    "\n",
    "\n",
    "def stringify_children(node):\n",
    "    \"\"\"\n",
    "    Filters and removes possible Nones in texts and tails\n",
    "    ref: http://stackoverflow.com/questions/4624062/get-all-text-inside-a-tag-in-lxml\n",
    "    \"\"\"\n",
    "    parts = ([node.text] +\n",
    "             list(chain(*([c.text, c.tail] for c in node.getchildren()))) +\n",
    "             [node.tail])\n",
    "    return ''.join(filter(None, parts))\n",
    "\n",
    "\n",
    "def stringify_affiliation(node):\n",
    "    \"\"\"\n",
    "    Filters and removes possible Nones in texts and tails\n",
    "    ref: http://stackoverflow.com/questions/4624062/get-all-text-inside-a-tag-in-lxml\n",
    "    \"\"\"\n",
    "    parts = ([node.text] +\n",
    "             list(chain(*([c.text if (c.tag != 'label' and c.tag !='sup') else '', c.tail] for c in node.getchildren()))) +\n",
    "             [node.tail])\n",
    "    return ' '.join(filter(None, parts))\n",
    "\n",
    "\n",
    "def recur_children(node):\n",
    "    \"\"\"\n",
    "    Recursive through node to when it has multiple children\n",
    "    \"\"\"\n",
    "    if len(node.getchildren()) == 0:\n",
    "        parts = ([node.text or ''] + [node.tail or '']) if (node.tag != 'label' and node.tag !='sup') else ([node.tail or ''])\n",
    "        return parts\n",
    "    else:\n",
    "        parts = ([node.text or ''] +\n",
    "                 [recur_children(c) for c in node.getchildren()] +\n",
    "                 [node.tail or ''])\n",
    "        return parts\n",
    "\n",
    "\n",
    "def stringify_affiliation_rec(node):\n",
    "    \"\"\"\n",
    "    Flatten and join list to string\n",
    "    ref: http://stackoverflow.com/questions/2158395/flatten-an-irregular-list-of-lists-in-python\n",
    "    \"\"\"\n",
    "    parts = recur_children(node)\n",
    "    return ' '.join(flatten(parts)).strip()\n",
    "\n",
    "\n",
    "def zip_author(author):\n",
    "    \"\"\"\n",
    "    Give a list of author and its affiliation keys\n",
    "    in this following format\n",
    "    [first_name, last_name, [key1, key2]]\n",
    "    return [[first_name, last_name, key1], [first_name, last_name, key2]] instead\n",
    "    \"\"\"\n",
    "    author_zipped = list(zip([[author[0], author[1]]]*len(author[-1]), author[-1]))\n",
    "    return map(lambda x: x[0] + [x[-1]], author_zipped)\n",
    "\n",
    "\n",
    "def flatten_zip_author(author_list):\n",
    "    \"\"\"\n",
    "    Apply zip_author to author_list and flatten it\n",
    "    \"\"\"\n",
    "    author_zipped_list = map(zip_author, author_list)\n",
    "    return list(chain.from_iterable(author_zipped_list))\n",
    "\n",
    "\n",
    "def parse_pubmed_xml(path, include_path=False):\n",
    "    \"\"\"\n",
    "    Given single xml path, extract information from xml file\n",
    "    and return parsed xml file in dictionary format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = etree.parse(path)\n",
    "    except:\n",
    "        try:\n",
    "            tree = etree.fromstring(path)\n",
    "        except:\n",
    "            raise Exception(\"It was not able to read a path, a file-like object, or a string as an XML\")\n",
    "\n",
    "    try:\n",
    "        title = ' '.join(tree.xpath('//title-group/article-title/text()')).replace('\\n', ' ')\n",
    "        sub_title = ' '.join(tree.xpath('//title-group/subtitle/text()')).replace('\\n', ' ').replace('\\t', ' ')\n",
    "        full_title = title + ' ' + sub_title\n",
    "    except:\n",
    "        full_title = ''\n",
    "    try:\n",
    "        abstract = ' '.join(tree.xpath('//abstract//text()'))\n",
    "    except:\n",
    "        abstract = ''\n",
    "    try:\n",
    "        journal_title = tree.xpath('//journal-title-group/journal-title')[0].text\n",
    "    except:\n",
    "        try:\n",
    "            journal_title = tree.xpath('/article/front/journal-meta/journal-title/text()')[0]\n",
    "        except:\n",
    "            journal_title = ''\n",
    "    try:\n",
    "        pmid = tree.xpath('//article-meta/article-id[@pub-id-type=\"pmid\"]')[0].text\n",
    "    except:\n",
    "        pmid = ''\n",
    "    try:\n",
    "        pmc = tree.xpath('//article-meta/article-id[@pub-id-type=\"pmc\"]')[0].text\n",
    "    except:\n",
    "        pmc = ''\n",
    "    try:\n",
    "        pub_id = tree.xpath('//article-meta/article-id[@pub-id-type=\"publisher-id\"]')[0].text\n",
    "    except:\n",
    "        pub_id = ''\n",
    "    try:\n",
    "        pub_year = tree.xpath('//pub-date/year/text()')[0]\n",
    "    except:\n",
    "        pub_year = ''\n",
    "    try:\n",
    "        subjects = ','.join(tree.xpath('//article-categories//subj-group//text()'))\n",
    "    except:\n",
    "        subjects = ''\n",
    "\n",
    "    # create affiliation dictionary\n",
    "    aff_id = tree.xpath('//aff[@id]/@id')\n",
    "    if len(aff_id) == 0:\n",
    "        aff_id = ['']  # replace id with empty list\n",
    "\n",
    "    aff_name = tree.xpath('//aff[@id]')\n",
    "    aff_name_list = []\n",
    "    for node in aff_name:\n",
    "        aff_name_list.append(stringify_affiliation_rec(node))\n",
    "    affiliation_list = map(list, zip(aff_id, map(lambda x: x.strip().replace('\\n', ' '), aff_name_list)))  # create dictionary\n",
    "\n",
    "    tree_author = tree.xpath('//contrib-group/contrib[@contrib-type=\"author\"]')\n",
    "\n",
    "    author_list = []\n",
    "    for el in tree_author:\n",
    "        el0 = el.findall('xref[@ref-type=\"aff\"]')\n",
    "        try:\n",
    "            rid_list = [tmp.attrib['rid'] for tmp in el0]\n",
    "        except:\n",
    "            rid_list = ''\n",
    "        try:\n",
    "            author_list.append([el.find('name/surname').text, el.find('name/given-names').text, rid_list])\n",
    "        except:\n",
    "            author_list.append(['', '', rid_list])\n",
    "    author_list = flatten_zip_author(author_list)\n",
    "\n",
    "    dict_out = {'full_title': full_title.strip(),\n",
    "                'abstract': abstract,\n",
    "                'journal_title': journal_title,\n",
    "                'pmid': pmid,\n",
    "                'pmc': pmc,\n",
    "                'publisher_id': pub_id,\n",
    "                'author_list': author_list,\n",
    "                'affiliation_list': affiliation_list,\n",
    "                'publication_year': pub_year,\n",
    "                'subjects': subjects}\n",
    "    if include_path:\n",
    "        dict_out['path_to_file'] = path\n",
    "    return dict_out\n",
    "\n",
    "\n",
    "def parse_pubmed_xml_to_df(paths, include_path=False, remove_abstract=False):\n",
    "    \"\"\"\n",
    "    Given list of xml paths, return parsed DataFrame\n",
    "\n",
    "    path_list: list of xml paths\n",
    "    remove_abs: if true, remove row of dataframe if parsed xml contains empty abstract\n",
    "    path_xml: if true, concat path to xml file when constructing DataFrame\n",
    "    \"\"\"\n",
    "    pm_docs = []\n",
    "    if not isinstance(paths, list):\n",
    "        pm_docs = [parse_pubmed_xml(paths, include_path=include_path)] # in case providing single path\n",
    "    else:\n",
    "        # else for list of paths\n",
    "        for path in paths:\n",
    "            pm_dict = parse_pubmed_xml(path, include_path=include_path)\n",
    "            pm_docs.append(pm_dict)\n",
    "\n",
    "    pm_docs = filter(partial(is_not, None), pm_docs)  # remove None\n",
    "    pm_docs_df = pd.DataFrame(pm_docs) # turn to pandas DataFrame\n",
    "\n",
    "    # remove empty abstract\n",
    "    if remove_abstract:\n",
    "        pm_docs_df = pm_docs_df[pm_docs_df.abstract != ''].reset_index().drop('index', axis=1)\n",
    "\n",
    "    return pm_docs_df\n",
    "\n",
    "\n",
    "def pretty_print_xml(path):\n",
    "    \"\"\"\n",
    "    Given a XML path, file-like, or string, print a pretty xml version of it\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = etree.parse(path)\n",
    "    except:\n",
    "        try:\n",
    "            tree = etree.fromstring(path)\n",
    "        except:\n",
    "            raise Exception(\"It was not able to read a path, a file-like object, or a string as an XML\")\n",
    "\n",
    "    print (tostring(tree, pretty_print=True))\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"\n",
    "    Yield successive n-sized chunks from l\n",
    "    Suppose we want to chunk all path list into smaller chunk\n",
    "    example: chunks(path_list, 10000)\n",
    "    \"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "# path_xml = list_xml_path('/Users/ptighe/Documents/Python Projects/AcutePainOntology/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xml = list_xml_path('/Users/ptighe/Documents/Python Projects/AcutePainOntology/xml_testing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}